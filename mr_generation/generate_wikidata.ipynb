{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHY60blE90rV",
        "outputId": "c996b515-6165-4613-d0b3-04b2c4865ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1 (from SPARQLWrapper)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->SPARQLWrapper)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-6.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBN1KBq0oEA3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ispaiz5_AQbj",
        "outputId": "c01262d4-ce36-471b-8c82-add2d7cbf271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqpm_YM_-Ns3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import csv\n",
        "import urllib.parse\n",
        "import re\n",
        "from SPARQLWrapper import JSON, SPARQLWrapper\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
        "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11\")\n",
        "\n",
        "\n",
        "prefix = \"\"\"\n",
        "\tPREFIX wd: <http://www.wikidata.org/entity/>\n",
        "    PREFIX wds: <http://www.wikidata.org/entity/statement/>\n",
        "    PREFIX wdv: <http://www.wikidata.org/value/>\n",
        "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
        "    PREFIX wikibase: <http://wikiba.se/ontology#>\n",
        "    PREFIX p: <http://www.wikidata.org/prop/>\n",
        "    PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
        "    PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
        "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "    PREFIX bd: <http://www.bigdata.com/rdf#>\n",
        "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "\"\"\"\n",
        "\n",
        "test_num = 100\n",
        "\n",
        "def write_csv(fname, data):\n",
        "\twith open(fname, 'w') as f:\n",
        "\t\twrite = csv.writer(f)\n",
        "\t\twrite.writerows(data)\n",
        "\n",
        "def query_sparql(query):\n",
        "\tsparql.setQuery(prefix+query)\n",
        "\tsparql.setReturnFormat(JSON)\n",
        "\n",
        "\tresults = sparql.query().convert()\n",
        "\n",
        "\treturn results\n",
        "\n",
        "\n",
        "\n",
        "def print_examples(training_data, test):\n",
        "\tnum = 2\n",
        "\tprint(\"training_data_example\")\n",
        "\tfor x in range(num):\n",
        "\t\tprint(training_data[x])\n",
        "\n",
        "\tprint()\n",
        "\tprint(\"test_data_example\")\n",
        "\tfor x in range(num):\n",
        "\t\tprint(test[x])\n",
        "\n",
        "def getPronouns(gender, val_type=\"subj\"):\n",
        "\tif gender == \"female\":\n",
        "\t\tif val_type == \"subj\":\n",
        "\t\t\treturn \"she\"\n",
        "\t\telif val_type == \"poss\" or val_type == \"obj\":\n",
        "\t\t\treturn \"her\"\n",
        "\telif gender == \"male\":\n",
        "\t\tif val_type == \"subj\":\n",
        "\t\t\treturn \"he\"\n",
        "\t\telif val_type == \"poss\":\n",
        "\t\t\treturn \"his\"\n",
        "\t\telif val_type == \"obj\":\n",
        "\t\t\treturn \"him\"\n",
        "\telse:\n",
        "\t\tif val_type == \"subj\":\n",
        "\t\t\treturn \"they\"\n",
        "\t\telif val_type == \"poss\":\n",
        "\t\t\treturn \"their\"\n",
        "\t\telif val_type == \"obj\":\n",
        "\t\t\treturn \"them\"\n",
        "\treturn \"they\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vBWbINuAPAW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "log_dir = '/content/drive/MyDrive/'\n",
        "def get_logging(logfile):\n",
        "    if not os.path.isdir(log_dir):\n",
        "        os.mkdir(log_dir)\n",
        "    log_path = os.path.join(log_dir, logfile)\n",
        "    logger = logging.getLogger(log_path)\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
        "                        datefmt='%m-%d %H:%M',\n",
        "                        # handlers=[logging.FileHandler(logfile)],\n",
        "                        filename=log_path,\n",
        "                        filemode='w'\n",
        "                        )\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTXh0yJtDz2A"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "#import logging_helper\n",
        "from collections import defaultdict\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "#PREFIXES = constants.PREFIXES\n",
        "PREFIXES = prefix\n",
        "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
        "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11\")\n",
        "\n",
        "logger = get_logging('/content')\n",
        "\n",
        "\n",
        "def clean_wikidata_id(wikidata_link):\n",
        "    return wikidata_link.replace('http://www.wikidata.org/entity/', '')\n",
        "\n",
        "class WikidataHelper():\n",
        "    def __init__(self, logger=logger, wikidata_host=WIKIDATA_ENDPOINT):\n",
        "        self.sparql = SPARQLWrapper(wikidata_host)\n",
        "        self.logger = logger   # if logger else logging_helper.get_logging('{}.log'.format(self.__class__.__name__))\n",
        "\n",
        "    def get_wikidata_id_by_label(self, entity_label, instance_of_id=None):\n",
        "        retval = None\n",
        "\n",
        "        if not entity_label:\n",
        "            return retval\n",
        "\n",
        "        instance_of_query = \"\"\"\n",
        "        BIND(wd:%s AS ?idType)\n",
        "        {?s wdt:P31 ?idType. }\n",
        "            UNION\n",
        "            {?s wdt:P31 ?idNode .\n",
        "            ?idNode wdt:P279 ?idType.}\n",
        "                UNION\n",
        "            {?s wdt:P31 ?idNode1 .\n",
        "            ?idNode1 wdt:P279 ?idNode2.\n",
        "            ?idNode2 wdt:P279 ?idType.}\n",
        "        \"\"\" % instance_of_id if instance_of_id else \"\"\n",
        "\n",
        "        query = \"\"\"\n",
        "        %s\n",
        "\n",
        "        SELECT ?s (COUNT(?oedge) as ?count)\n",
        "        WHERE\n",
        "        {\n",
        "\n",
        "\n",
        "            ?s rdfs:label '%s'@en .\n",
        "            ?s wdt:P31 ?instance_of.\n",
        "            FILTER (?instance_of not in ( wd:Q4167410 )  ) # filter disambiguation page\n",
        "            %s\n",
        "            ?s ?oedge ?other .\n",
        "\n",
        "        } GROUP BY ?s ORDER BY DESC(?count)\n",
        "        \"\"\" % (PREFIXES, entity_label, instance_of_query)\n",
        "        self.sparql.setQuery(query)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        try:\n",
        "            results = self.sparql.query().convert()\n",
        "            retval = clean_wikidata_id(results['results']['bindings'][0]['s']['value'])\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[get_wikidata_id_by_label] Exception: {}\\nquery={}\".format(e, query))\n",
        "        return retval\n",
        "\n",
        "\n",
        "    def get_instance_of(self, wikidata_id):\n",
        "        \"\"\"\n",
        "\n",
        "        :param wikidata_id:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        retval = []\n",
        "        if not wikidata_id:\n",
        "            return retval\n",
        "        query = \"\"\"\n",
        "        %s\n",
        "        SELECT DISTINCT ?oLabel\n",
        "        WHERE\n",
        "        {   wd:%s wdt:P31 ?o .\n",
        "            ?o rdfs:label ?oLabel\n",
        "            FILTER ( lang(?oLabel) = \"en\" )\n",
        "\n",
        "\n",
        "        }\n",
        "        \"\"\" % (PREFIXES, wikidata_id)\n",
        "        self.sparql.setQuery(query)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        try:\n",
        "            results = self.sparql.query().convert()\n",
        "            retval = [x['oLabel']['value'] for x in results['results']['bindings']]\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[get_instance_of] Exception: {}\\nquery={}\".format(e, query))\n",
        "        return retval\n",
        "\n",
        "    def get_entity_all_outgoing_relations(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        all info includes all statements and identifiers in Wikidata page. Exclude alias, description\n",
        "        :param wikidata_id:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        retval = {}\n",
        "\n",
        "        if not wikidata_id:\n",
        "            return retval\n",
        "\n",
        "        query = \"\"\"\n",
        "        %s\n",
        "        SELECT DISTINCT ?sLabel ?rel ?relName ?o ?oLabel\n",
        "        WHERE\n",
        "        {   wd:%s rdfs:label ?sLabel .\n",
        "            wd:%s ?directClaimP ?o .          # Get the truthy triples.\n",
        "            ?rel wikibase:directClaim ?directClaimP . # Find the Wikibase properties linked\n",
        "                             # to the truthy triples' predicates\n",
        "\n",
        "         FILTER (lang(?sLabel) = 'en')\n",
        "\n",
        "         OPTIONAL {\n",
        "           ?rel rdfs:label ?relName .\n",
        "            FILTER ( lang(?relName) = \"en\" )  }\n",
        "         OPTIONAL {\n",
        "            ?o rdfs:label ?oLabel\n",
        "            FILTER ( lang(?oLabel) = \"en\" )\n",
        "           }\n",
        "\n",
        "        }\n",
        "        \"\"\"% (PREFIXES, wikidata_id, wikidata_id)\n",
        "        self.sparql.setQuery(query)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        try:\n",
        "            results = self.sparql.query().convert()\n",
        "            entity_lable = results['results']['bindings'][0]['sLabel']['value']\n",
        "            retval['label'] = entity_lable\n",
        "            relations = {}\n",
        "\n",
        "            for r in results['results']['bindings']:\n",
        "                relation_id = clean_wikidata_id(r['rel']['value'])\n",
        "                object_id = clean_wikidata_id(r['o']['value']) if 'oLabel' in r else None\n",
        "                object_label = r['oLabel']['value'] if 'oLabel' in r else r['o']['value']\n",
        "                if relation_id in relations:\n",
        "                    relations[relation_id]['values'].append({'object_id': object_id, 'object_label': object_label})\n",
        "                else:\n",
        "                    relations[relation_id] = {}\n",
        "                    relations[relation_id]['relation_label'] = r['relName']['value']\n",
        "                    relations[relation_id]['values'] = [{'object_id': object_id, 'object_label': object_label}]\n",
        "\n",
        "            retval['relations'] = relations\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[get_entity_all_info] Exception: {}\\nquery={}\".format(e, query))\n",
        "        return retval\n",
        "\n",
        "    def get_entity_all_incoming_relations(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        get all direct incoming relations\n",
        "        :param wikidata_id:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        retval = {}\n",
        "\n",
        "        if not wikidata_id:\n",
        "            return retval\n",
        "\n",
        "        query = \"\"\"\n",
        "        %s\n",
        "        SELECT DISTINCT  ?s ?sLabel ?rel ?relName ?oLabel\n",
        "        WHERE\n",
        "        {   wd:%s rdfs:label ?oLabel .\n",
        "\n",
        "            ?s ?directClaimP wd:%s .          # Get the truthy triples.\n",
        "            ?rel wikibase:directClaim ?directClaimP . # Find the Wikibase properties linked to the truthy triples' predicates\n",
        "\n",
        "\n",
        "         FILTER (lang(?oLabel) = 'en')\n",
        "\n",
        "         OPTIONAL {\n",
        "           ?rel rdfs:label ?relName .\n",
        "            FILTER ( lang(?relName) = \"en\" )  }\n",
        "         OPTIONAL {\n",
        "            ?s rdfs:label ?sLabel\n",
        "            FILTER ( lang(?sLabel) = \"en\" )\n",
        "           }\n",
        "        }\n",
        "        \"\"\" % (PREFIXES, wikidata_id, wikidata_id)\n",
        "        self.sparql.setQuery(query)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        try:\n",
        "            results = self.sparql.query().convert()\n",
        "            entity_lable = results['results']['bindings'][0]['oLabel']['value']\n",
        "            retval['label'] = entity_lable\n",
        "            relations = {}\n",
        "\n",
        "            for r in results['results']['bindings']:\n",
        "                relation_id = clean_wikidata_id(r['rel']['value'])\n",
        "                subject_id = clean_wikidata_id(r['s']['value']) if 'sLabel' in r else None\n",
        "                subject_label = r['sLabel']['value'] if 'sLabel' in r else r['s']['value']\n",
        "                if relation_id in relations:\n",
        "                    relations[relation_id]['values'].append({'subject_id': subject_id, 'subject_label': subject_label})\n",
        "                else:\n",
        "                    relations[relation_id] = {}\n",
        "                    relations[relation_id]['relation_label'] = r['relName']['value']\n",
        "                    relations[relation_id]['values'] = [{'subject_id': subject_id, 'subject_label': subject_label}]\n",
        "\n",
        "            retval['relations'] = relations\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[get_entity_incoming_edges] Exception: {}\\nquery={}\".format(e, query))\n",
        "        return retval\n",
        "\n",
        "\n",
        "    def get_entity_relation(self, wikidata_id, relation_id, is_outgoing_relation=True):\n",
        "        \"\"\"\n",
        "        Get specific incoming/outgoing relation info\n",
        "        :param wikidata_id: wikidata id for the node\n",
        "        :param relation_id: wikidata id for the specific relation\n",
        "        :param is_outgoing_relation: True for outgoing relations, False for incoming ones.\n",
        "        :return: list of linked nodes with the wikidata_id and title.\n",
        "        \"\"\"\n",
        "        retval = []\n",
        "\n",
        "        if not wikidata_id:\n",
        "            return retval\n",
        "\n",
        "        relation_query = \"wd:{} wdt:{} ?otherNode\".format(wikidata_id, relation_id) if is_outgoing_relation \\\n",
        "            else '?otherNode wdt:{} wd:{}'.format(relation_id, wikidata_id)\n",
        "\n",
        "        query = \"\"\"\n",
        "        %s\n",
        "        SELECT DISTINCT  ?otherNode ?otherNodeLabel\n",
        "        WHERE\n",
        "        {   wd:%s rdfs:label ?nodeLabel .\n",
        "\n",
        "            %s\n",
        "\n",
        "         FILTER (lang(?nodeLabel) = 'en')\n",
        "\n",
        "         OPTIONAL {\n",
        "            ?otherNode rdfs:label ?otherNodeLabel\n",
        "            FILTER ( lang(?otherNodeLabel) = \"en\" )\n",
        "           }\n",
        "        }\n",
        "        \"\"\" % (PREFIXES, wikidata_id, relation_query)\n",
        "        self.sparql.setQuery(query)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        try:\n",
        "            results = self.sparql.query().convert()\n",
        "\n",
        "            for r in results['results']['bindings']:\n",
        "                retval.append({\n",
        "                    'label': clean_wikidata_id(r['otherNodeLabel']['value']),\n",
        "                    'wikidata_id': clean_wikidata_id(r['otherNode']['value'])\n",
        "                })\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[get_entity_relation] Exception: {}\\nquery={}\".format(e, query))\n",
        "        return retval\n",
        "\n",
        "\n",
        "    def get_two_hop_path(self, source_node_id, target_node_id):\n",
        "        \"\"\"\n",
        "        Find 2 hop path between source node and target node\n",
        "\n",
        "\n",
        "        :param source_node_id:\n",
        "        :param target_node_id:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        query = f\"\"\"\n",
        "        {PREFIXES}\n",
        "        SELECT DISTINCT  ?sourceNodeLabel ?relation1Label ?bridgeNode ?bridgeNodeLabel ?relation2Label ?targetNodeLabel\n",
        "        WHERE\n",
        "        {{   wd:{source_node_id} rdfs:label ?sourceNodeLabel .\n",
        "            wd:{target_node_id} rdfs:label ?targetNodeLabel .\n",
        "         FILTER (lang(?sourceNodeLabel) = 'en')\n",
        "         FILTER (lang(?targetNodeLabel) = 'en')\n",
        "\n",
        "         # relation: source -> relation1 -> bridge node -> relation2 -> target node\n",
        "        {{ wd:{source_node_id} ?directClaimP ?bridgeNode .\n",
        "            ?relations1 wikibase:directClaim ?directClaimP .\n",
        "           ?bridgeNode ?otherDirectClaimP wd:{target_node_id} .\n",
        "            ?relations2 wikibase:directClaim ?otherDirectClaimP .}}\n",
        "\n",
        "         # relation: source -> relation1 -> bridge node <- relation2 <- target node\n",
        "         UNION {{\n",
        "            wd:{source_node_id} ?directClaimP ?bridgeNode .\n",
        "           ?relations1 wikibase:directClaim ?directClaimP .\n",
        "           wd:{target_node_id} ?otherDirectClaimP ?bridgeNode  .\n",
        "           ?relations2 wikibase:directClaim ?otherDirectClaimP .\n",
        "         }}\n",
        "\n",
        "         # relation: source <- relations1 <- bridge node <- relations2 <- target node\n",
        "        UNION {{\n",
        "           ?bridgeNode ?directClaimP wd:{source_node_id}.\n",
        "           ?relations1 wikibase:directClaim ?directClaimP .\n",
        "           wd:{target_node_id} ?otherDirectClaimP ?bridgeNode  .\n",
        "           ?relations2 wikibase:directClaim ?otherDirectClaimP .\n",
        "         }}\n",
        "\n",
        "         # relation: source <- relations1 <- bridge node -> relations2 -> target node\n",
        "        UNION {{\n",
        "         ?bridgeNode ?directClaimP wd:{source_node_id}.\n",
        "           ?relations1 wikibase:directClaim ?directClaimP .\n",
        "           ?bridgeNode ?otherDirectClaimP wd:{target_node_id}   .\n",
        "           ?relations2 wikibase:directClaim ?otherDirectClaimP .\n",
        "         }}\n",
        "\n",
        "\n",
        "         OPTIONAL {{\n",
        "            ?bridgeNode rdfs:label ?bridgeNodeLabel\n",
        "            FILTER ( lang(?bridgeNodeLabel) = \"en\" )\n",
        "           }}\n",
        "\n",
        "         OPTIONAL {{\n",
        "           ?relations1 rdfs:label ?relation1Label\n",
        "                      FILTER ( lang(?relation1Label) = \"en\" )\n",
        "         }}\n",
        "         OPTIONAL {{\n",
        "           ?relations2 rdfs:label ?relation2Label\n",
        "                           FILTER ( lang(?relation2Label) = \"en\" )\n",
        "         }}\n",
        "        }}\n",
        "\n",
        "        \"\"\"\n",
        "        retval = []\n",
        "        self.sparql.setQuery(query)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        try:\n",
        "            results = self.sparql.query().convert()\n",
        "\n",
        "            for r in results['results']['bindings']:\n",
        "                retval.append({\n",
        "                    'sourceNodeLabel': r['sourceNodeLabel']['value'],\n",
        "                    'relation1Label': r['relation1Label']['value'],\n",
        "                    'bridgeNode': clean_wikidata_id(r['bridgeNode']['value']),\n",
        "                    'bridgeNodeLabel': r['bridgeNodeLabel']['value'],\n",
        "                    'relation2Label': r['relation2Label']['value'],\n",
        "                    'targetNodeLabel': r['targetNodeLabel']['value']})\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[get_two_hop_path] Exception: {}\\nquery={}\".format(e, query))\n",
        "        return retval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LaKRoaNF7EvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "20b154f7-c03c-4e98-d163-acd326199e99"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-865f662d6404>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpop_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/KG-NLG Capstone 2023/popularity_data/sports_popularity.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpop_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m filter_list = ['table_tennis_player', 'golfer', 'field_hockey_player', 'canadian_football_player', 'badminton_player', 'volleyball_player', 'swimmer', 'boxer', 'rugby_player',\n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m'tennis_player'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ice_hockey_player'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m'baseball_player'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cricketer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'american_football_player'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "pop_df = pd.read_csv(\"/content/drive/MyDrive/KG-NLG Capstone 2023/popularity_data/sports_popularity.csv\")\n",
        "pop_df['entity_type'].unique()\n",
        "filter_list = ['table_tennis_player', 'golfer', 'field_hockey_player', 'canadian_football_player', 'badminton_player', 'volleyball_player', 'swimmer', 'boxer', 'rugby_player',\n",
        "                'tennis_player', 'ice_hockey_player',\n",
        "                'baseball_player', 'cricketer', 'american_football_player',\n",
        "                'soccer_player', 'basketball_player']\n",
        "\n",
        "# Filter the DataFrame based on the filter list\n",
        "filtered_pop_df = pop_df[pop_df['entity_type'].isin(filter_list)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35yvM9nppMf1"
      },
      "source": [
        "# get one hop data for 30 popular sports figure and 30 not so popular figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "XdS_lmCUpLzy",
        "outputId": "f5d39ad8-bc3f-4f48-fa25-20223d5f2e7a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b9304246c30c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_pop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sort the DataFrame by count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_pop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filtered_pop_df' is not defined"
          ]
        }
      ],
      "source": [
        "player1 = filtered_pop_df.sort_values(\"count\", ascending=False).reset_index()  # Sort the DataFrame by count\n",
        "player2 = filtered_pop_df.sort_values(\"count\", ascending=False)\n",
        "player2 = player2[int(len(player2)/64):].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i57P7eEppzXn",
        "outputId": "a394607a-63a0-4061-8b0c-acab124a4d06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b99cf729-8673-42ca-91a5-2ed2b7808d8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>entity_type</th>\n",
              "      <th>wikidata_label</th>\n",
              "      <th>wikidata_label_clean</th>\n",
              "      <th>wikidata_description</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>alias</th>\n",
              "      <th>date</th>\n",
              "      <th>wikipedia_link</th>\n",
              "      <th>wikipedia_title</th>\n",
              "      <th>wikipedia_title_clean</th>\n",
              "      <th>wikidata_id</th>\n",
              "      <th>count</th>\n",
              "      <th>domain_mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>432611</td>\n",
              "      <td>1137394</td>\n",
              "      <td>2</td>\n",
              "      <td>soccer_player</td>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Argentine association football player</td>\n",
              "      <td>nm2177779</td>\n",
              "      <td>male</td>\n",
              "      <td>Messi | Leo Messi | Lionel Andres Messi | Lion...</td>\n",
              "      <td>1987-06-24</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Lionel_Messi</td>\n",
              "      <td>Lionel_Messi</td>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Q615</td>\n",
              "      <td>3816771.0</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>142129</td>\n",
              "      <td>236549</td>\n",
              "      <td>150</td>\n",
              "      <td>soccer_player</td>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Portuguese footballer (born 1985)</td>\n",
              "      <td>nm1860184</td>\n",
              "      <td>male</td>\n",
              "      <td>Ronaldo | CR7 | Cristiano Ronaldo dos Santos A...</td>\n",
              "      <td>1985-02-05</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Cristiano_Ronaldo</td>\n",
              "      <td>Cristiano_Ronaldo</td>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Q11571</td>\n",
              "      <td>3382718.0</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6794</td>\n",
              "      <td>9711</td>\n",
              "      <td>2825</td>\n",
              "      <td>tennis_player</td>\n",
              "      <td>George VI</td>\n",
              "      <td>George VI</td>\n",
              "      <td>King of the United Kingdom from 1936 to 1952, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>Bertie | Albert Windsor | George Windsor | Alb...</td>\n",
              "      <td>1895-12-14</td>\n",
              "      <td>https://en.wikipedia.org/wiki/George_VI</td>\n",
              "      <td>George_VI</td>\n",
              "      <td>George VI</td>\n",
              "      <td>Q280856</td>\n",
              "      <td>2274593.0</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>280839</td>\n",
              "      <td>703013</td>\n",
              "      <td>214075</td>\n",
              "      <td>soccer_player</td>\n",
              "      <td>Erling Haaland</td>\n",
              "      <td>Erling Haaland</td>\n",
              "      <td>Norwegian footballer (born 2000)</td>\n",
              "      <td>nm10994643</td>\n",
              "      <td>male</td>\n",
              "      <td>Erling Braut Haaland | Erling Braut Håland | E...</td>\n",
              "      <td>2000-07-21</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Erling_Haaland</td>\n",
              "      <td>Erling_Haaland</td>\n",
              "      <td>Erling Haaland</td>\n",
              "      <td>Q28967995</td>\n",
              "      <td>1684726.0</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>201112</td>\n",
              "      <td>426833</td>\n",
              "      <td>7994</td>\n",
              "      <td>basketball_player</td>\n",
              "      <td>Brittney Griner</td>\n",
              "      <td>Brittney Griner</td>\n",
              "      <td>American basketball player</td>\n",
              "      <td>nm5330249</td>\n",
              "      <td>female</td>\n",
              "      <td>Brittney Yevette Griner</td>\n",
              "      <td>1990-10-18</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Brittney_Griner</td>\n",
              "      <td>Brittney_Griner</td>\n",
              "      <td>Brittney Griner</td>\n",
              "      <td>Q2925780</td>\n",
              "      <td>1534569.0</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738648</th>\n",
              "      <td>783107</td>\n",
              "      <td>2282266</td>\n",
              "      <td>137253</td>\n",
              "      <td>basketball_player</td>\n",
              "      <td>Megan Pinske</td>\n",
              "      <td>Megan Pinske</td>\n",
              "      <td>Canadian basketball player</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1988-10-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q112800121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738649</th>\n",
              "      <td>783108</td>\n",
              "      <td>2282267</td>\n",
              "      <td>137254</td>\n",
              "      <td>basketball_player</td>\n",
              "      <td>Laurelle Weigl</td>\n",
              "      <td>Laurelle Weigl</td>\n",
              "      <td>Canadian basketball player</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1988-04-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q112800421</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738650</th>\n",
              "      <td>783109</td>\n",
              "      <td>2282268</td>\n",
              "      <td>137255</td>\n",
              "      <td>basketball_player</td>\n",
              "      <td>Leighann Doan</td>\n",
              "      <td>Leighann Doan</td>\n",
              "      <td>Canadian basketball player</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1978-11-06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q112800963</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738651</th>\n",
              "      <td>783110</td>\n",
              "      <td>2282269</td>\n",
              "      <td>137256</td>\n",
              "      <td>basketball_player</td>\n",
              "      <td>Alex Anderson</td>\n",
              "      <td>Alex Anderson</td>\n",
              "      <td>American basketball player</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1986-02-21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q112691972</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738652</th>\n",
              "      <td>783111</td>\n",
              "      <td>2282270</td>\n",
              "      <td>137257</td>\n",
              "      <td>basketball_player</td>\n",
              "      <td>Marko Kovačević</td>\n",
              "      <td>Marko Kovačević</td>\n",
              "      <td>Serbian basketball player</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1999-07-29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q112701954</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>738653 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b99cf729-8673-42ca-91a5-2ed2b7808d8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b99cf729-8673-42ca-91a5-2ed2b7808d8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b99cf729-8673-42ca-91a5-2ed2b7808d8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        level_0  Unnamed: 0   index        entity_type     wikidata_label  \\\n",
              "0        432611     1137394       2      soccer_player       Lionel Messi   \n",
              "1        142129      236549     150      soccer_player  Cristiano Ronaldo   \n",
              "2          6794        9711    2825      tennis_player          George VI   \n",
              "3        280839      703013  214075      soccer_player     Erling Haaland   \n",
              "4        201112      426833    7994  basketball_player    Brittney Griner   \n",
              "...         ...         ...     ...                ...                ...   \n",
              "738648   783107     2282266  137253  basketball_player       Megan Pinske   \n",
              "738649   783108     2282267  137254  basketball_player     Laurelle Weigl   \n",
              "738650   783109     2282268  137255  basketball_player      Leighann Doan   \n",
              "738651   783110     2282269  137256  basketball_player      Alex Anderson   \n",
              "738652   783111     2282270  137257  basketball_player    Marko Kovačević   \n",
              "\n",
              "       wikidata_label_clean  \\\n",
              "0              Lionel Messi   \n",
              "1         Cristiano Ronaldo   \n",
              "2                 George VI   \n",
              "3            Erling Haaland   \n",
              "4           Brittney Griner   \n",
              "...                     ...   \n",
              "738648         Megan Pinske   \n",
              "738649       Laurelle Weigl   \n",
              "738650        Leighann Doan   \n",
              "738651        Alex Anderson   \n",
              "738652      Marko Kovačević   \n",
              "\n",
              "                                     wikidata_description     imdb_id  gender  \\\n",
              "0                   Argentine association football player   nm2177779    male   \n",
              "1                       Portuguese footballer (born 1985)   nm1860184    male   \n",
              "2       King of the United Kingdom from 1936 to 1952, ...         NaN    male   \n",
              "3                        Norwegian footballer (born 2000)  nm10994643    male   \n",
              "4                              American basketball player   nm5330249  female   \n",
              "...                                                   ...         ...     ...   \n",
              "738648                         Canadian basketball player         NaN  female   \n",
              "738649                         Canadian basketball player         NaN  female   \n",
              "738650                         Canadian basketball player         NaN  female   \n",
              "738651                         American basketball player         NaN  female   \n",
              "738652                          Serbian basketball player         NaN    male   \n",
              "\n",
              "                                                    alias        date  \\\n",
              "0       Messi | Leo Messi | Lionel Andres Messi | Lion...  1987-06-24   \n",
              "1       Ronaldo | CR7 | Cristiano Ronaldo dos Santos A...  1985-02-05   \n",
              "2       Bertie | Albert Windsor | George Windsor | Alb...  1895-12-14   \n",
              "3       Erling Braut Haaland | Erling Braut Håland | E...  2000-07-21   \n",
              "4                                 Brittney Yevette Griner  1990-10-18   \n",
              "...                                                   ...         ...   \n",
              "738648                                                NaN  1988-10-31   \n",
              "738649                                                NaN  1988-04-05   \n",
              "738650                                                NaN  1978-11-06   \n",
              "738651                                                NaN  1986-02-21   \n",
              "738652                                                NaN  1999-07-29   \n",
              "\n",
              "                                         wikipedia_link    wikipedia_title  \\\n",
              "0            https://en.wikipedia.org/wiki/Lionel_Messi       Lionel_Messi   \n",
              "1       https://en.wikipedia.org/wiki/Cristiano_Ronaldo  Cristiano_Ronaldo   \n",
              "2               https://en.wikipedia.org/wiki/George_VI          George_VI   \n",
              "3          https://en.wikipedia.org/wiki/Erling_Haaland     Erling_Haaland   \n",
              "4         https://en.wikipedia.org/wiki/Brittney_Griner    Brittney_Griner   \n",
              "...                                                 ...                ...   \n",
              "738648                                              NaN                NaN   \n",
              "738649                                              NaN                NaN   \n",
              "738650                                              NaN                NaN   \n",
              "738651                                              NaN                NaN   \n",
              "738652                                              NaN                NaN   \n",
              "\n",
              "       wikipedia_title_clean wikidata_id      count domain_mapping  \n",
              "0               Lionel Messi        Q615  3816771.0         sports  \n",
              "1          Cristiano Ronaldo      Q11571  3382718.0         sports  \n",
              "2                  George VI     Q280856  2274593.0         sports  \n",
              "3             Erling Haaland   Q28967995  1684726.0         sports  \n",
              "4            Brittney Griner    Q2925780  1534569.0         sports  \n",
              "...                      ...         ...        ...            ...  \n",
              "738648                   NaN  Q112800121        NaN         sports  \n",
              "738649                   NaN  Q112800421        NaN         sports  \n",
              "738650                   NaN  Q112800963        NaN         sports  \n",
              "738651                   NaN  Q112691972        NaN         sports  \n",
              "738652                   NaN  Q112701954        NaN         sports  \n",
              "\n",
              "[738653 rows x 17 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "player1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aInWy4cHjaN-"
      },
      "outputs": [],
      "source": [
        "helper = WikidataHelper()\n",
        "helper.get_entity_all_incoming_relations('Q169138')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-R_lh4juO4k",
        "outputId": "be62944f-0271-4511-db49-4b67330fd43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first\n",
            "0 :  30\n",
            "1 :  30\n",
            "2 :  30\n",
            "3 :  30\n",
            "4 :  30\n",
            "5 :  30\n",
            "6 :  30\n",
            "7 :  30\n",
            "8 :  30\n",
            "9 :  30\n",
            "10 :  30\n",
            "11 :  30\n",
            "12 :  30\n",
            "13 :  30\n",
            "14 :  30\n",
            "15 :  30\n",
            "16 :  30\n",
            "17 :  30\n",
            "18 :  30\n",
            "19 :  30\n",
            "20 :  30\n",
            "21 :  30\n",
            "22 :  30\n",
            "23 :  30\n",
            "24 :  30\n",
            "25 :  30\n",
            "26 :  30\n",
            "27 :  30\n",
            "28 :  30\n",
            "29 :  30\n",
            "second\n",
            "0 :  30\n",
            "1 :  30\n",
            "2 :  30\n",
            "3 :  30\n",
            "4 :  30\n",
            "5 :  30\n",
            "6 :  30\n",
            "7 :  30\n",
            "8 :  30\n",
            "9 :  30\n",
            "10 :  30\n",
            "11 :  30\n",
            "12 :  30\n",
            "13 :  30\n",
            "14 :  30\n",
            "15 :  30\n",
            "16 :  30\n",
            "17 :  30\n",
            "18 :  30\n",
            "19 :  30\n",
            "20 :  30\n",
            "21 :  30\n",
            "22 :  30\n",
            "23 :  30\n",
            "24 :  30\n",
            "25 :  30\n",
            "26 :  30\n",
            "27 :  30\n",
            "28 :  30\n",
            "29 :  30\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "cutoff_values = [40, 5, 0]\n",
        "rating_val = ['excellent', 'good', 'okay']\n",
        "# rating_val = ['excellent', 'good', 'okay', 'poor']\n",
        "def check_value(dictionary, value):\n",
        "    for inner_dict in dictionary.values():\n",
        "        if value in inner_dict.values():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def process_data(data):\n",
        "    for key, value in data.items():\n",
        "        if isinstance(value, str) and value == \"\":\n",
        "            data[key] = \"N/A\"\n",
        "        elif isinstance(value, list) and value == []:\n",
        "            data[key] = [\"N/A\"]\n",
        "    return data\n",
        "\n",
        "def get_topn_data(df, n, req_lst):\n",
        "    helper = WikidataHelper()\n",
        "    full_data = []\n",
        "    count = 0\n",
        "    unique = []\n",
        "    for index, player in df.iterrows():\n",
        "        player_data = {\"name\":\"\", \"sport\":\"\", \"team_positions\":[], \"awards\":[],\n",
        "                       \"dob\":\"\", \"pob\":\"\", \"sports_teams\":[], \"height\":\"\", \"start_time\":\"\",\n",
        "                       \"num_awards\":0, \"stats_leader\": [], \"rating\":\"\", \"wiki_id\":\"\"}\n",
        "        player_data['wiki_id'] = player['wikidata_id']\n",
        "        player_q = helper.get_entity_all_outgoing_relations(player['wikidata_id'])\n",
        "        incoming_player_q = helper.get_entity_all_incoming_relations(player['wikidata_id'])\n",
        "        count_flg = 0\n",
        "        while 'label' not in player_q and count_flg <= 1:\n",
        "            time.sleep(1)\n",
        "            player_q = helper.get_entity_all_outgoing_relations(player['wikidata_id'])\n",
        "            count_flg+=1\n",
        "        if count_flg >= 2:\n",
        "            continue\n",
        "\n",
        "        count_flg = 0\n",
        "        while 'label' not in incoming_player_q and count_flg <= 1:\n",
        "            time.sleep(1)\n",
        "            incoming_player_q = helper.get_entity_all_incoming_relations(player['wikidata_id'])\n",
        "            count_flg+=1\n",
        "        if count_flg >= 2:\n",
        "            continue\n",
        "\n",
        "        player_data['name'] = df['wikidata_label_clean']\n",
        "\n",
        "        if all(check_value(player_q['relations'], value) for value in req_lst) and player_q['label'] not in unique:\n",
        "            print(count, \": \", n)\n",
        "            unique.append(player_q['label'])\n",
        "            if 'label' in incoming_player_q:\n",
        "                for relation in incoming_player_q['relations'].values():\n",
        "                    if relation['relation_label'] == 'statistical leader':\n",
        "                        for val in relation['values']:\n",
        "                            player_data['stats_leader'].append(val['object_label'])\n",
        "            for relation in player_q['relations'].values():\n",
        "                if relation['relation_label'] == 'place of birth':\n",
        "                    player_data['pob'] = relation['values'][0]['object_label']\n",
        "                elif relation['relation_label'] == 'position played on team / speciality':\n",
        "                    for val in relation['values']:\n",
        "                        player_data['team_positions'].append(val['object_label'])\n",
        "                elif relation['relation_label'] == 'statistical leader':\n",
        "                    for val in relation['values']:\n",
        "                        player_data['stats_leader'].append(val['object_label'])\n",
        "                elif relation['relation_label'] == 'work period (start)':\n",
        "                    try:\n",
        "                        dt = datetime.strptime(relation['values'][0]['object_label'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "                        output_string = dt.strftime(\"%Y\")\n",
        "                        player_data[\"start_time\"] = output_string\n",
        "                    except ValueError:\n",
        "                        player_data[\"start_time\"] = relation['values'][0]['object_label']\n",
        "                        pass\n",
        "                elif relation['relation_label'] == 'member of sports team':\n",
        "                    for val in relation['values']:\n",
        "                        player_data['sports_teams'].append(val['object_label'])\n",
        "                elif relation['relation_label'] == 'sport':\n",
        "                    player_data['sport'] = relation['values'][0]['object_label']\n",
        "                elif relation['relation_label'] == 'award received':\n",
        "                    for val in relation['values']:\n",
        "                        player_data['awards'].append(val['object_label'])\n",
        "                    player_data['num_awards'] = len(player_data['awards'])\n",
        "                elif relation['relation_label'] == 'height':\n",
        "                    player_data['height'] = relation['values'][0]['object_label']\n",
        "                elif relation['relation_label'] == 'date of birth':\n",
        "                    try:\n",
        "                        dt = datetime.strptime(relation['values'][0]['object_label'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "                        output_string = dt.strftime('%B %d, %Y').replace(' 0', ' ')\n",
        "                        player_data[\"dob\"] = output_string\n",
        "                    except ValueError:\n",
        "                        player_data[\"dob\"] = relation['values'][0]['object_label']\n",
        "                        pass\n",
        "                for i, v in enumerate(cutoff_values):\n",
        "                    if player_data['num_awards'] >= v:\n",
        "                        player_data[\"rating\"] = rating_val[i]\n",
        "                        break\n",
        "            player_data = process_data(player_data)\n",
        "            full_data.append(player_data)\n",
        "            count += 1\n",
        "            if count == n:\n",
        "                return pd.DataFrame(full_data)\n",
        "        else:\n",
        "            continue\n",
        "    return pd.DataFrame(full_data)\n",
        "\n",
        "required_attribute_list = ['place of birth',\n",
        "                           'work period (start)',\n",
        "                           'sport', 'height', 'date of birth']\n",
        "print(\"first\")\n",
        "df1 = get_topn_data(player1, 30, required_attribute_list)\n",
        "print(\"second\")\n",
        "df2 = get_topn_data(player2, 30, required_attribute_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "LMPCnFKXc3IN",
        "outputId": "c123ad01-5c5e-4255-ad86-9395ae84a594"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e94a6761e253>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mlook_table_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/sport_select.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mlook_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wiki_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlook_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_wikidata_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mlook_table_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/athlete_select.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e94a6761e253>\u001b[0m in \u001b[0;36mget_wikidata_id\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m'search'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     }\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    715\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs_5M7HLARnD"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df1, df2])\n",
        "df.to_csv('/content/drive/MyDrive/sport_select.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiHOP\n"
      ],
      "metadata": {
        "id": "yCCuZ6g2QhJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaRdTWbI7BDY"
      },
      "outputs": [],
      "source": [
        "# get popularity data\n",
        "def top_n_pruning(lst, n, visited):\n",
        "    count_dict = dict(zip(pop_df['wikidata_id'], pop_df['count']))\n",
        "    for item in lst:\n",
        "        object_id = item.get('object_id', None)\n",
        "        subject_id = item.get('subject_id', None)\n",
        "        if object_id is not None:\n",
        "            count = count_dict.get(object_id, 0)\n",
        "        elif subject_id is not None:\n",
        "            count = count_dict.get(subject_id, 0)\n",
        "        else:\n",
        "            count = 0\n",
        "        item['count'] = count\n",
        "    sorted_list = sorted(lst, key=lambda x: x['count'], reverse=True)\n",
        "    filtered_data = [item for item in sorted_list if ('object_id' not in item or item['object_id'] not in visited) and ('subject_id' not in item or item['subject_id'] not in visited)]\n",
        "    if len(filtered_data) == 0:\n",
        "        return None\n",
        "    else:\n",
        "        return filtered_data[:n]\n",
        "\n",
        "def filter_sentences(sentences, mandatory):\n",
        "    filtered_sentences = []\n",
        "    for path_str, words in sentences:\n",
        "        if all(word in path_str for word in mandatory):\n",
        "            filtered_sentences.append((path_str, words))\n",
        "    return filtered_sentences\n",
        "\n",
        "\n",
        "from typing import List, Tuple\n",
        "from datetime import datetime\n",
        "SAVED_NODES_OUT = {}\n",
        "SAVED_NODES_IN = {}\n",
        "def generate_n_hop_paths(helper, q_node: str, n_hops: int, cur_str: str = '', cur_hop: int = 0, visited: set = None,\n",
        "                         mandatory_list: set = None, excluded_list: set = None, keep_list: set = None, branch: bool = False) -> List[Tuple[str, List[str]]]:\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "    visited.add(q_node)\n",
        "\n",
        "\n",
        "    if cur_hop == n_hops:\n",
        "        return [(cur_str, [q_node])]\n",
        "\n",
        "    if q_node not in SAVED_NODES_OUT:\n",
        "        time.sleep(1)\n",
        "        outgoing_relations = helper.get_entity_all_outgoing_relations(q_node)\n",
        "        SAVED_NODES_OUT[q_node] = outgoing_relations\n",
        "    else:\n",
        "        outgoing_relations = SAVED_NODES_OUT[q_node]\n",
        "    if q_node not in SAVED_NODES_IN:\n",
        "        time.sleep(1)\n",
        "        incoming_relations = helper.get_entity_all_incoming_relations(q_node)\n",
        "        SAVED_NODES_IN[q_node] = incoming_relations\n",
        "    else:\n",
        "        incoming_relations = SAVED_NODES_IN[q_node]\n",
        "    paths = []\n",
        "    #keep_list = ['part of', 'performer', 'tracklist', 'record label', 'genre']\n",
        "    # Process outgoing relations\n",
        "    for r in outgoing_relations:\n",
        "        if r == 'label' and cur_hop == 0:\n",
        "            start_node = outgoing_relations[r]\n",
        "            cur_str = start_node\n",
        "        elif r != 'label':\n",
        "            for rels in outgoing_relations[r]:\n",
        "                relation_label = outgoing_relations[r][rels]['relation_label']\n",
        "                if relation_label in keep_list:\n",
        "                    if len(outgoing_relations[r][rels]['values']) > 10:\n",
        "                        pruned_list = top_n_pruning(outgoing_relations[r][rels]['values'], 10, visited)\n",
        "                    else:\n",
        "                        pruned_list = outgoing_relations[r][rels]['values']\n",
        "                    if pruned_list is None:  # Check if pruned_list is None\n",
        "                        continue\n",
        "                    for val in pruned_list:\n",
        "                        if relation_label == \"publication date\":\n",
        "                            try:\n",
        "                                dt = datetime.strptime(val[\"object_label\"], '%Y-%m-%dT%H:%M:%SZ')\n",
        "                                updated_str = cur_str + \" --> \" + relation_label + ' --> ' + dt.strftime(\"%Y\")\n",
        "                            except ValueError:\n",
        "                                pass\n",
        "                        else:\n",
        "                            updated_str = cur_str + \" --> \" + relation_label + ' --> ' + val['object_label']\n",
        "                        next_q_node = val['object_id']\n",
        "                        new_visited = visited.copy()\n",
        "                        new_visited.add(next_q_node)\n",
        "                        sub_paths = generate_n_hop_paths(helper, next_q_node, n_hops,\n",
        "                                                         updated_str, cur_hop + 1, new_visited,\n",
        "                                                         mandatory_list, excluded_list, keep_list, branch)\n",
        "                        for sub_path in sub_paths:\n",
        "                            path_str, q_nodes = sub_path\n",
        "                            paths.append((path_str, [q_node] + q_nodes))\n",
        "\n",
        "    # Process incoming relations\n",
        "    for r in incoming_relations:\n",
        "        if r != 'label':\n",
        "            for rels in incoming_relations[r]:\n",
        "                relation_label = incoming_relations[r][rels]['relation_label']\n",
        "                if relation_label in keep_list:\n",
        "                    if len(incoming_relations[r][rels]['values']) > 10:\n",
        "                        pruned_list = top_n_pruning(incoming_relations[r][rels]['values'], 10, visited)\n",
        "                    else:\n",
        "                        pruned_list = incoming_relations[r][rels]['values']\n",
        "                    if pruned_list is None:  # Check if pruned_list is None\n",
        "                        continue\n",
        "                    for val in pruned_list:\n",
        "                        updated_str = cur_str + \" --> \" + \"~\" + relation_label + ' --> ' + val['subject_label']\n",
        "                        prev_q_node = val['subject_id']\n",
        "                        new_visited = visited.copy()\n",
        "                        new_visited.add(prev_q_node)\n",
        "                        sub_paths = generate_n_hop_paths(helper, prev_q_node,\n",
        "                                                         n_hops, updated_str, cur_hop + 1,\n",
        "                                                         new_visited, mandatory_list,\n",
        "                                                         excluded_list, keep_list, branch)\n",
        "                        for sub_path in sub_paths:\n",
        "                            path_str, q_nodes = sub_path\n",
        "                            paths.append((path_str, [q_node] + q_nodes))\n",
        "    paths = filter_sentences(paths, mandatory_list)\n",
        "    if len(paths) > 10:\n",
        "        paths = paths[:10]\n",
        "    return paths\n",
        "\n",
        "import random\n",
        "def generate_trees(shape_inp, shape_num_hops, start_q_node, n_hops, mandatory_list, excluded_list, full_list, branch):\n",
        "    helper = WikidataHelper()\n",
        "    ori_path_list = generate_n_hop_paths(helper, start_q_node, n_hops,\n",
        "                                         mandatory_list=mandatory_list,\n",
        "                                         excluded_list=excluded_list,\n",
        "                                         keep_list=full_list)\n",
        "    #if len(shape_inp)==0:\n",
        "    #    return ori_path_list\n",
        "    aditional_path_list = []\n",
        "    final_path = []\n",
        "    for (path, nodes) in ori_path_list:\n",
        "        skip = False\n",
        "        temp_str = path\n",
        "        temp_nodes = []\n",
        "        for i, shape in enumerate(shape_inp):\n",
        "            additions = generate_n_hop_paths(helper, nodes[shape], shape_num_hops[i],\n",
        "                                             mandatory_list=mandatory_list,\n",
        "                                             excluded_list=excluded_list,\n",
        "                                             keep_list=full_list, branch=branch)\n",
        "            addition_path = [t[0] for t in additions]   # [1, 2, 3]\n",
        "            addition_q_node = [t[1] for t in additions]\n",
        "            non_overlapping_nodes = []\n",
        "            non_overlapping_paths = []\n",
        "            for n, p in zip(addition_q_node, addition_path):\n",
        "                if n[1] not in nodes and n[1] not in temp_nodes:\n",
        "                    non_overlapping_nodes.append(n)\n",
        "                    non_overlapping_paths.append(p)\n",
        "            if len(non_overlapping_paths) != 0:\n",
        "                index = random.randint(0, len(non_overlapping_paths)-1)\n",
        "                temp_str+= ' | ' + non_overlapping_paths[index]\n",
        "                temp_nodes.append(non_overlapping_nodes[index])\n",
        "            else:\n",
        "                skip = True\n",
        "                break\n",
        "        if skip == True:\n",
        "            continue\n",
        "        final_path.append(temp_str)\n",
        "    return final_path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    helper = WikidataHelper()\n",
        "    \"\"\"\n",
        "    n_hops = 2\n",
        "    shape = [0]\n",
        "    n_hops_shape = [1]\n",
        "\n",
        "    \"\"\"\n",
        "    n_hops = 2\n",
        "    shape = [0, 0]\n",
        "    n_hops_shape = [1, 2]\n",
        "    start_q_node = 'Q18786715'\n",
        "\n",
        "    # path_list = generate_n_hop_paths(helper, start_q_node, n_hops)\n",
        "    #path_list = generate_trees(shape, n_hops_shape, start_q_node, n_hops)\n",
        "    #for p in path_list:\n",
        "    #   print(p)\n",
        "   # result = helper.get_two_hop_path(source_node_id='Q37175', target_node_id='Q295463')\n",
        "   # for r in result:\n",
        "   #    print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3P4zHZz1rTG"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "df_sum = pd.read_csv(\"/content/drive/MyDrive/athlete_select.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9hn1zO1B4Zm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Open the JSON file\n",
        "with open('/content/drive/MyDrive/athlete_path_constraints.json', 'r') as file:\n",
        "    # Load the JSON data\n",
        "    slot_dict = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "xZBxEs4rTtci",
        "outputId": "83371705-9a11-43c6-a512-4d82d6ed863d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-66e7a2152e09>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mpath_to_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/shapes.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mgenerate_paths_with_da_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecifier_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'slot_dict' is not defined"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "def remove_prefix(strings):\n",
        "    return [\" --> \".join(string.split(' --> ')[2:]) for string in strings]\n",
        "\n",
        "def replace(strings, rating):\n",
        "    flag = False\n",
        "    final_out = []\n",
        "    name = strings[0].split(' | ')[0].split(' --> ')[0]\n",
        "    for i, string in enumerate(strings):\n",
        "        seperate_lst = string.split(' | ')\n",
        "        modified = []\n",
        "        for item in seperate_lst:\n",
        "            if len(item.split(' --> '))==3 and flag == False:\n",
        "                modified.append(name + \" --> rating --> \" + rating)\n",
        "                flag = True\n",
        "            else:\n",
        "                modified.append(item)\n",
        "        final_out.append(\" | \".join(modified))\n",
        "    return final_out\n",
        "\n",
        "\n",
        "def add_rating(strings, rating):\n",
        "    return [rating + \" --> ~rating --> \" + string for string in strings]\n",
        "def add_specifiers(strings, specifiers):\n",
        "    return [random.choice(specifiers) + \" --> ~specifier --> \" + string for string in strings]\n",
        "\n",
        "def generate_paths_with_da_constraints(path_to_shapes, slot_dict, specifiers):\n",
        "    info = pd.read_csv(path_to_shapes)\n",
        "    paths = []\n",
        "    rating_df = pd.read_csv(\"/content/drive/MyDrive/athlete_select.csv\")\n",
        "    for da, value in slot_dict.items():\n",
        "        mand = value['mandatory']\n",
        "        excld = value['excluded']\n",
        "        full = value['full']\n",
        "        min_slots = value['min_slots']\n",
        "        max_slots = value['max_slots']\n",
        "        for index, row in info.iterrows():\n",
        "            if row['not generate'] == 'X' or row['num_nodes'] < min_slots or row['num_nodes'] > max_slots:\n",
        "                continue\n",
        "            branch_loc = ast.literal_eval(row['branch_loc'])\n",
        "            n_hops_shape = ast.literal_eval(row['n_hops_shape'])\n",
        "            n_hops = row[\"Depth/Hops\"]\n",
        "            shape = row['Shape']\n",
        "            for n, song in df_sum.iterrows():\n",
        "                print(\"DA:{} shape:{} {}:60\".format(da, shape, n))\n",
        "                print(song['wiki_id'])\n",
        "                if row['branch'] == \"no\":\n",
        "                    branch = False\n",
        "                else:\n",
        "                    branch = True\n",
        "\n",
        "                if da == \"give_opinion\" or da == \"verify_attribute\":\n",
        "                    path_list = generate_trees(branch_loc, n_hops_shape, song['wiki_id'], n_hops-1, mand, excld, full, branch)\n",
        "                else:\n",
        "                    path_list = generate_trees(branch_loc, n_hops_shape, song['wiki_id'], n_hops, mand, excld, full, branch)\n",
        "                count = 0\n",
        "                while len(path_list) == 0 and count <=3:\n",
        "                    del SAVED_NODES_OUT[song['wiki_id']]\n",
        "                    del SAVED_NODES_IN[song['wiki_id']]\n",
        "                    if da == \"give_opinion\":\n",
        "                        path_list = generate_trees(branch_loc, n_hops_shape, song['wiki_id'], n_hops-1, mand, excld, full, branch)\n",
        "                    else:\n",
        "                        path_list = generate_trees(branch_loc, n_hops_shape, song['wiki_id'], n_hops, mand, excld, full, branch)\n",
        "                    count += 1\n",
        "                if da == \"request_explanation\":\n",
        "                    path_list = remove_prefix(path_list)\n",
        "                    rating=rating_df.loc[n]['rating']\n",
        "                    path_list = add_rating(path_list, rating)\n",
        "                elif da == \"request\":\n",
        "                    path_list = remove_prefix(path_list)\n",
        "                    path_list = add_specifiers(path_list, specifiers)\n",
        "                elif da == \"give_opinion\" or da == \"verify_attribute\":\n",
        "                    rating=rating_df.loc[n]['rating']\n",
        "                    path_list = add_rating(path_list, rating)\n",
        "                elif da == \"inform\" and row['inform replace rating']=='yes' and random.random() < 1/10:\n",
        "                    rating=rating_df.loc[n]['rating']\n",
        "                    if len(path_list) == 0:\n",
        "                        continue\n",
        "                    path_list = replace(path_list, rating)\n",
        "\n",
        "                for p in path_list:\n",
        "                    path_data = {\"da\":da, \"shape\":shape, \"path\":p, \"n_hops\":n_hops}\n",
        "                    paths.append(path_data)\n",
        "                df = pd.DataFrame(paths)\n",
        "                df.to_csv(\"/content/drive/MyDrive/athlete_path_with_shapes.csv\", index=False)\n",
        "            print(len(SAVED_NODES_OUT))\n",
        "            print(len(SAVED_NODES_IN))\n",
        "            with open(\"/content/drive/MyDrive/out_info.json\", 'wb') as json_file:\n",
        "                pickle.dump(SAVED_NODES_OUT, json_file)\n",
        "\n",
        "            with open(\"/content/drive/MyDrive/in_info.json\", 'wb') as json_file_1:\n",
        "                pickle.dump(SAVED_NODES_IN, json_file_1)\n",
        "\n",
        "            with open(\"/content/drive/MyDrive/out_info.json\", 'rb') as file:\n",
        "                SAVED_NODES_OUT = pickle.load(file)\n",
        "\n",
        "            with open(\"/content/drive/MyDrive/in_info.json\", 'rb') as file:\n",
        "                SAVED_NODES_IN = pickle.load(file)\n",
        "\n",
        "specifier_list = ['gifted', 'accomplished', 'seasoned', 'boring', 'inadequate', 'unlucky', \"underated\", \"overrated\"]\n",
        "path_to_shapes = \"/content/drive/MyDrive/shapes.csv\"\n",
        "\n",
        "generate_paths_with_da_constraints(path_to_shapes, slot_dict, specifier_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7VGP9Z-59IX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oPVRV0ZdSqB"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/org_paths.csv')\n",
        "import pandas as pd\n",
        "import re\n",
        "def add_pseudo_mr_columns(df):\n",
        "    def get_pseudo_mr_1(path):\n",
        "        tokens = path.split(\" --> \")\n",
        "        return \" \".join([tokens[i] for i in range(0, len(tokens), 2)])\n",
        "\n",
        "    def get_pseudo_mr_2(path):\n",
        "        old_toks = path.split(\" --> \")\n",
        "        tokens = []\n",
        "        for i, item in enumerate(old_toks):\n",
        "            tokens.append(item)\n",
        "            if i!=0 and i % 2 == 0 and i!=len(old_toks)-1:\n",
        "                tokens.append(old_toks[i])\n",
        "        for i, tok in enumerate(tokens):\n",
        "            if '~' in tok:\n",
        "                tokens[i] = tokens[i][1:]\n",
        "                tokens[i+1], tokens[i-1] = tokens[i-1], tokens[i+1]\n",
        "        cur_str = ''\n",
        "        for i in range(0, len(tokens), 3):\n",
        "            cur_str += tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \". \"\n",
        "\n",
        "        return cur_str\n",
        "\n",
        "\n",
        "    df[\"pseudo_mr_1\"] = df[\"path\"].apply(get_pseudo_mr_1)\n",
        "    df[\"pseudo_mr_2\"] = df[\"path\"].apply(get_pseudo_mr_2)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "adjusted_df=add_pseudo_mr_columns(df)\n",
        "adjusted_df.to_csv('/content/drive/MyDrive/mr_paths.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMj3fwYd-TiJ"
      },
      "outputs": [],
      "source": [
        " class SongQueries(object):\n",
        "    SONG_ALL  = \"\"\"\n",
        "    SELECT ?song ?songLabel ?publication ?genreLabel ?labelLabel ?performerLabel ?view ?producerLabel ?instanceLabel ?partLabel ?tracklistLabel\n",
        "    {\n",
        "        BIND(wd:%s AS ?song)\n",
        "\n",
        "        ?song rdfs:label ?songLabel .\n",
        "        FILTER(LANG(?songLabel) = \"en\") .\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P31 ?instance.\n",
        "            ?instance rdfs:label ?instanceLabel .\n",
        "            FILTER(LANG(?instanceLabel) = \"en\") .\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song p:P1651 ?youtubeID .\n",
        "            ?youtubeID pq:P5436 ?view.\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P162 ?producer.\n",
        "            ?producer rdfs:label ?producerLabel .\n",
        "            FILTER(LANG(?producerLabel) = \"en\") .\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P175 ?performer.\n",
        "            ?performer rdfs:label ?performerLabel .\n",
        "            FILTER(LANG(?performerLabel) = \"en\") .\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P136 ?genre.\n",
        "            ?genre rdfs:label ?genreLabel .\n",
        "            FILTER(LANG(?genreLabel) = \"en\") .\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P264 ?label.\n",
        "            ?label rdfs:label ?labelLabel .\n",
        "            FILTER(LANG(?labelLabel) = \"en\") .\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P577 ?publication.\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P361 ?part.\n",
        "            ?part rdfs:label ?partLabel .\n",
        "            FILTER(LANG(?partLabel) = \"en\") .\n",
        "        }\n",
        "        OPTIONAL\n",
        "        {\n",
        "            ?song wdt:P361 ?album.\n",
        "            ?album wdt:P658 ?tracklist.\n",
        "            ?tracklist rdfs:label ?tracklistLabel .\n",
        "            FILTER(LANG(?tracklistLabel) = \"en\") .\n",
        "        }\n",
        "    }\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDtU94A6-a0E",
        "outputId": "a2f96489-44aa-4b95-cde1-c9935c5e3dde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-118-2bfe5b239b8f>:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  songs = pd.read_csv(\"/content/drive/MyDrive/Copy of music_popularity.csv\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "songs = pd.read_csv(\"/content/drive/MyDrive/Copy of music_popularity.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pstOsiSFCWOf",
        "outputId": "4022e4a7-023b-446a-a23f-7e048ad98197"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Blurred Lines'"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "c0xngO2lpFSa",
        "outputId": "07750b85-5176-417f-fe38-0801bff86d26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e69c304-9a60-4c2a-beaf-bb6cd240eaeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>entity_type</th>\n",
              "      <th>wikidata_label</th>\n",
              "      <th>wikidata_label_clean</th>\n",
              "      <th>wikidata_description</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>alias</th>\n",
              "      <th>date</th>\n",
              "      <th>wikipedia_link</th>\n",
              "      <th>wikipedia_title</th>\n",
              "      <th>wikipedia_title_clean</th>\n",
              "      <th>wikidata_id</th>\n",
              "      <th>count</th>\n",
              "      <th>domain_mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22712</th>\n",
              "      <td>292460</td>\n",
              "      <td>1</td>\n",
              "      <td>song</td>\n",
              "      <td>Never Gonna Give You Up</td>\n",
              "      <td>Never Gonna Give You Up</td>\n",
              "      <td>song written and composed by Stock Aitken Wate...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1987-01-01</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Never_Gonna_Give...</td>\n",
              "      <td>Never_Gonna_Give_You_Up</td>\n",
              "      <td>Never Gonna Give You Up</td>\n",
              "      <td>Q57</td>\n",
              "      <td>175164.0</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22713</th>\n",
              "      <td>292461</td>\n",
              "      <td>27</td>\n",
              "      <td>song</td>\n",
              "      <td>Goldfinger</td>\n",
              "      <td>Goldfinger</td>\n",
              "      <td>theme song of the James Bond film</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Theme from « Goldfinger »</td>\n",
              "      <td>1964-01-01</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Goldfinger_(Shir...</td>\n",
              "      <td>Goldfinger_(Shirley_Bassey_song)</td>\n",
              "      <td>Goldfinger Shirley Bassey song</td>\n",
              "      <td>Q14716</td>\n",
              "      <td>8991.0</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22714</th>\n",
              "      <td>292462</td>\n",
              "      <td>50</td>\n",
              "      <td>song</td>\n",
              "      <td>The Way You Make Me Feel</td>\n",
              "      <td>The Way You Make Me Feel</td>\n",
              "      <td>original song written and composed by Michael ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1987-01-01</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Way_You_Make...</td>\n",
              "      <td>The_Way_You_Make_Me_Feel</td>\n",
              "      <td>The Way You Make Me Feel</td>\n",
              "      <td>Q14651</td>\n",
              "      <td>23275.0</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22715</th>\n",
              "      <td>292463</td>\n",
              "      <td>61</td>\n",
              "      <td>song</td>\n",
              "      <td>Im Wartesaal zum großen Glück</td>\n",
              "      <td>Im Wartesaal zum großen Glück</td>\n",
              "      <td>Walter Andreas Schwarz song</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Das Lied vom großen Glück | \"Im Wartesaal zum ...</td>\n",
              "      <td>1956-01-01</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Im_Wartesaal_zum...</td>\n",
              "      <td>Im_Wartesaal_zum_gro%C3%9Fen_Gl%C3%BCck</td>\n",
              "      <td>Im Wartesaal zum gro%C3%9Fen Gl%C3%BCck</td>\n",
              "      <td>Q82525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22716</th>\n",
              "      <td>292464</td>\n",
              "      <td>121</td>\n",
              "      <td>song</td>\n",
              "      <td>Feel the Love</td>\n",
              "      <td>Feel the Love</td>\n",
              "      <td>Rudimental song</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-05-14</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Feel_the_Love_(R...</td>\n",
              "      <td>Feel_the_Love_(Rudimental_song)</td>\n",
              "      <td>Feel the Love Rudimental song</td>\n",
              "      <td>Q21083</td>\n",
              "      <td>3007.0</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456263</th>\n",
              "      <td>1709193</td>\n",
              "      <td>139986</td>\n",
              "      <td>song</td>\n",
              "      <td>Hello Future</td>\n",
              "      <td>Hello Future</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-04-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q113044415</td>\n",
              "      <td>NaN</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456264</th>\n",
              "      <td>1709194</td>\n",
              "      <td>139987</td>\n",
              "      <td>song</td>\n",
              "      <td>Re:RISE -e.p.- 2</td>\n",
              "      <td>ReRISE  e.p.  2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-08-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q113045163</td>\n",
              "      <td>NaN</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456265</th>\n",
              "      <td>1709195</td>\n",
              "      <td>139988</td>\n",
              "      <td>song</td>\n",
              "      <td>Re:RISE -e.p.-</td>\n",
              "      <td>ReRISE  e.p.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-10-23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q113045180</td>\n",
              "      <td>NaN</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456266</th>\n",
              "      <td>1709196</td>\n",
              "      <td>139989</td>\n",
              "      <td>song</td>\n",
              "      <td>Sayonara namida/Hoshi no kakera</td>\n",
              "      <td>Sayonara namidaHoshi no kakera</td>\n",
              "      <td>2020 Spira Spica single</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-12-09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q113045146</td>\n",
              "      <td>NaN</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456267</th>\n",
              "      <td>1709197</td>\n",
              "      <td>139990</td>\n",
              "      <td>song</td>\n",
              "      <td>Time Passages / Almost Lucy</td>\n",
              "      <td>Time Passages  Almost Lucy</td>\n",
              "      <td>1978 single by Al Stewart</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Time Passages | Almost Lucy</td>\n",
              "      <td>1978-09-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q113077489</td>\n",
              "      <td>NaN</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142271 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e69c304-9a60-4c2a-beaf-bb6cd240eaeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e69c304-9a60-4c2a-beaf-bb6cd240eaeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e69c304-9a60-4c2a-beaf-bb6cd240eaeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0   index entity_type                   wikidata_label  \\\n",
              "22712       292460       1        song          Never Gonna Give You Up   \n",
              "22713       292461      27        song                       Goldfinger   \n",
              "22714       292462      50        song         The Way You Make Me Feel   \n",
              "22715       292463      61        song    Im Wartesaal zum großen Glück   \n",
              "22716       292464     121        song                    Feel the Love   \n",
              "...            ...     ...         ...                              ...   \n",
              "456263     1709193  139986        song                     Hello Future   \n",
              "456264     1709194  139987        song                 Re:RISE -e.p.- 2   \n",
              "456265     1709195  139988        song                   Re:RISE -e.p.-   \n",
              "456266     1709196  139989        song  Sayonara namida/Hoshi no kakera   \n",
              "456267     1709197  139990        song      Time Passages / Almost Lucy   \n",
              "\n",
              "                  wikidata_label_clean  \\\n",
              "22712          Never Gonna Give You Up   \n",
              "22713                       Goldfinger   \n",
              "22714         The Way You Make Me Feel   \n",
              "22715    Im Wartesaal zum großen Glück   \n",
              "22716                    Feel the Love   \n",
              "...                                ...   \n",
              "456263                    Hello Future   \n",
              "456264                 ReRISE  e.p.  2   \n",
              "456265                   ReRISE  e.p.    \n",
              "456266  Sayonara namidaHoshi no kakera   \n",
              "456267      Time Passages  Almost Lucy   \n",
              "\n",
              "                                     wikidata_description imdb_id gender  \\\n",
              "22712   song written and composed by Stock Aitken Wate...     NaN    NaN   \n",
              "22713                   theme song of the James Bond film     NaN    NaN   \n",
              "22714   original song written and composed by Michael ...     NaN    NaN   \n",
              "22715                         Walter Andreas Schwarz song     NaN    NaN   \n",
              "22716                                     Rudimental song     NaN    NaN   \n",
              "...                                                   ...     ...    ...   \n",
              "456263                                                NaN     NaN    NaN   \n",
              "456264                                                NaN     NaN    NaN   \n",
              "456265                                                NaN     NaN    NaN   \n",
              "456266                            2020 Spira Spica single     NaN    NaN   \n",
              "456267                          1978 single by Al Stewart     NaN    NaN   \n",
              "\n",
              "                                                    alias        date  \\\n",
              "22712                                                 NaN  1987-01-01   \n",
              "22713                           Theme from « Goldfinger »  1964-01-01   \n",
              "22714                                                 NaN  1987-01-01   \n",
              "22715   Das Lied vom großen Glück | \"Im Wartesaal zum ...  1956-01-01   \n",
              "22716                                                 NaN  2012-05-14   \n",
              "...                                                   ...         ...   \n",
              "456263                                                NaN  2018-04-25   \n",
              "456264                                                NaN  2020-08-05   \n",
              "456265                                                NaN  2019-10-23   \n",
              "456266                                                NaN  2020-12-09   \n",
              "456267                        Time Passages | Almost Lucy  1978-09-01   \n",
              "\n",
              "                                           wikipedia_link  \\\n",
              "22712   https://en.wikipedia.org/wiki/Never_Gonna_Give...   \n",
              "22713   https://en.wikipedia.org/wiki/Goldfinger_(Shir...   \n",
              "22714   https://en.wikipedia.org/wiki/The_Way_You_Make...   \n",
              "22715   https://en.wikipedia.org/wiki/Im_Wartesaal_zum...   \n",
              "22716   https://en.wikipedia.org/wiki/Feel_the_Love_(R...   \n",
              "...                                                   ...   \n",
              "456263                                                NaN   \n",
              "456264                                                NaN   \n",
              "456265                                                NaN   \n",
              "456266                                                NaN   \n",
              "456267                                                NaN   \n",
              "\n",
              "                                wikipedia_title  \\\n",
              "22712                   Never_Gonna_Give_You_Up   \n",
              "22713          Goldfinger_(Shirley_Bassey_song)   \n",
              "22714                  The_Way_You_Make_Me_Feel   \n",
              "22715   Im_Wartesaal_zum_gro%C3%9Fen_Gl%C3%BCck   \n",
              "22716           Feel_the_Love_(Rudimental_song)   \n",
              "...                                         ...   \n",
              "456263                                      NaN   \n",
              "456264                                      NaN   \n",
              "456265                                      NaN   \n",
              "456266                                      NaN   \n",
              "456267                                      NaN   \n",
              "\n",
              "                          wikipedia_title_clean wikidata_id     count  \\\n",
              "22712                   Never Gonna Give You Up         Q57  175164.0   \n",
              "22713            Goldfinger Shirley Bassey song      Q14716    8991.0   \n",
              "22714                  The Way You Make Me Feel      Q14651   23275.0   \n",
              "22715   Im Wartesaal zum gro%C3%9Fen Gl%C3%BCck      Q82525       NaN   \n",
              "22716             Feel the Love Rudimental song      Q21083    3007.0   \n",
              "...                                         ...         ...       ...   \n",
              "456263                                      NaN  Q113044415       NaN   \n",
              "456264                                      NaN  Q113045163       NaN   \n",
              "456265                                      NaN  Q113045180       NaN   \n",
              "456266                                      NaN  Q113045146       NaN   \n",
              "456267                                      NaN  Q113077489       NaN   \n",
              "\n",
              "       domain_mapping  \n",
              "22712           music  \n",
              "22713           music  \n",
              "22714           music  \n",
              "22715           music  \n",
              "22716           music  \n",
              "...               ...  \n",
              "456263          music  \n",
              "456264          music  \n",
              "456265          music  \n",
              "456266          music  \n",
              "456267          music  \n",
              "\n",
              "[142271 rows x 16 columns]"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "song = songs[songs.entity_type == \"song\"]\n",
        "song"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t91gWwSCp319"
      },
      "outputs": [],
      "source": [
        "# Get the value of the \"count\" column for each quartile cutoff row\n",
        "cutoff_values = [10000000, 100000, 10000, 1000]\n",
        "rating_val = ['excellent', 'good', 'mediocre', 'bad']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3FCz_B_ybpW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "-jRpSnFDK8X-",
        "outputId": "2e2e6e89-0fe6-4abc-c00f-abb80f479b68"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-58699b0a6d37>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sort the DataFrame by count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# extract the middle 200 values from the \"count\" column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'song' is not defined"
          ]
        }
      ],
      "source": [
        "song = song.sort_values(\"count\", ascending=False)  # Sort the DataFrame by count\n",
        "\n",
        "# extract the middle 200 values from the \"count\" column\n",
        "song = song[int(len(song)/8):].reset_index()\n",
        "song"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsOrNZPnDu3r",
        "outputId": "229d4b1d-c0ec-4e7a-9cea-cfd926f005d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-5c466b16662c>:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  songs = pd.read_csv(\"/content/drive/MyDrive/Copy of music_popularity.csv\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "5bnwUWPL8yjs",
        "outputId": "5f4034fa-d445-45fe-9f2b-ac9931be9030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DA:inform 0:60\n",
            "['genres'] ['publication date'] ['genres', 'producer', 'record label', 'performer', 'instance of', 'part of', 'track list']\n",
            "DA:inform 1:60\n",
            "['genres'] ['publication date'] ['genres', 'producer', 'record label', 'performer', 'instance of', 'part of', 'track list']\n",
            "DA:inform 2:60\n",
            "['genres'] ['publication date'] ['genres', 'producer', 'record label', 'performer', 'instance of', 'part of', 'track list']\n",
            "DA:inform 3:60\n",
            "['genres'] ['publication date'] ['genres', 'producer', 'record label', 'performer', 'instance of', 'part of', 'track list']\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-08bd54786611>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                        \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"genres\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"producer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"record label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"performer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"instance of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"part of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"track list\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                        'max_hops':3, 'min_slots':3, 'max_slots':8}}\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mgenerate_paths_with_da_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecifier_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-08bd54786611>\u001b[0m in \u001b[0;36mgenerate_paths_with_da_constraints\u001b[0;34m(path_to_shapes, slot_dict, specifiers)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mandatory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'excluded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mpath_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hops_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wikidata_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mandatory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'excluded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mpath_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"da\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_hops\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_hops\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0736587f6d93>\u001b[0m in \u001b[0;36mgenerate_trees\u001b[0;34m(shape_inp, shape_num_hops, start_q_node, n_hops, mandatory_list, excluded_list, full_list, branch)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_num_hops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_q_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmandatory_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcluded_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0mhelper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWikidataHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m     ori_path_list = generate_n_hop_paths(helper, start_q_node, n_hops, \n\u001b[0m\u001b[1;32m    452\u001b[0m                                          \u001b[0mmandatory_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmandatory_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                                          \u001b[0mexcluded_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcluded_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0736587f6d93>\u001b[0m in \u001b[0;36mgenerate_n_hop_paths\u001b[0;34m(helper, q_node, n_hops, cur_str, cur_hop, visited, mandatory_list, excluded_list, keep_list, branch)\u001b[0m\n\u001b[1;32m    411\u001b[0m                         \u001b[0mnew_visited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0mnew_visited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_q_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                         sub_paths = generate_n_hop_paths(helper, next_q_node, n_hops, \n\u001b[0m\u001b[1;32m    414\u001b[0m                                                          \u001b[0mupdated_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_hop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_visited\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                                                          mandatory_list, excluded_list, keep_list, branch)\n",
            "\u001b[0;32m<ipython-input-21-0736587f6d93>\u001b[0m in \u001b[0;36mgenerate_n_hop_paths\u001b[0;34m(helper, q_node, n_hops, cur_str, cur_hop, visited, mandatory_list, excluded_list, keep_list, branch)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0moutgoing_relations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAVED_NODES_OUT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mq_node\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVED_NODES_IN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mincoming_relations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entity_all_incoming_relations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mSAVED_NODES_IN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_node\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincoming_relations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0736587f6d93>\u001b[0m in \u001b[0;36mget_entity_all_incoming_relations\u001b[0;34m(self, wikidata_id)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetReturnFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mentity_lable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bindings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'oLabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mretval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_lable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/SPARQLWrapper/Wrapper.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mQueryResult\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \"\"\"\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mQueryResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueryAndConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"QueryResult.ConvertResult\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/SPARQLWrapper/Wrapper.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnFormat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    537\u001b[0m                                   '_open', req)\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1392\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lit0s73zin8x",
        "outputId": "2ea95013-30c2-4f51-9899-49a3fe7d9c55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Taylor Swift --> genre --> pop music',\n",
              " 'Taylor Swift --> genre --> country music',\n",
              " 'Taylor Swift --> genre --> pop rock',\n",
              " 'Taylor Swift --> genre --> synth-pop',\n",
              " 'Taylor Swift --> genre --> indie folk',\n",
              " 'Taylor Swift --> genre --> country pop']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K7FQnEc-ks-",
        "outputId": "81069ef3-31eb-4648-917e-ab79f7b2ba55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-121-1e3be9bbee43>:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  pop_df = pd.read_csv(\"/content/drive/MyDrive/Copy of music_popularity.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bar:  1 30\n",
            "bar:  2 30\n",
            "bar:  3 30\n",
            "bar:  4 30\n",
            "bar:  5 30\n",
            "bar:  6 30\n",
            "bar:  7 30\n",
            "bar:  8 30\n",
            "bar:  9 30\n",
            "bar:  10 30\n",
            "bar:  11 30\n",
            "bar:  12 30\n",
            "bar:  13 30\n",
            "bar:  14 30\n",
            "bar:  15 30\n",
            "bar:  16 30\n",
            "bar:  17 30\n",
            "bar:  18 30\n",
            "bar:  19 30\n",
            "bar:  20 30\n",
            "bar:  21 30\n",
            "bar:  22 30\n",
            "bar:  23 30\n",
            "bar:  24 30\n",
            "bar:  25 30\n",
            "bar:  26 30\n",
            "bar:  27 30\n",
            "bar:  28 30\n",
            "bar:  29 30\n",
            "bar:  30 30\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import time\n",
        "all_data = []\n",
        "songleng = len(song)\n",
        "counter = 0\n",
        "max = 1\n",
        "pop_df = pd.read_csv(\"/content/drive/MyDrive/Copy of music_popularity.csv\")\n",
        "song_ids = []\n",
        "for n, songId in enumerate(song[\"wikidata_id\"]):\n",
        "    if counter == 30:\n",
        "        break\n",
        "    # print(n, \"--\", songleng)\n",
        "    songName = song[\"wikipedia_title\"][n]\n",
        "\n",
        "   # print(bookId, bookName)\n",
        "   # ?songLabel ?performerLabel ?publication ?genreLabel ?labelLabel\n",
        "\n",
        "    songs_data = {\"name\":\"\", \"performer\":[], \"producer\":[], \"publication_date\":\"\",\n",
        "                  \"publication_year\":\"\", \"genres\":[], \"record_label\":[], \"rating\":\"\",\n",
        "                  \"instance_of\":[], \"is_from_album\":\"\", \"from_album\":\"\", \"songs_in_album\":[],\n",
        "                  \"two_hop\":[], \"three_hop\":[], \"four_hop\":[], \"five_hop\":[]}\n",
        "    # performersQ = query_sparql(SongQueries.SONG_PERFORMER  % (songId))\n",
        "    othersQ = query_sparql(SongQueries.SONG_ALL  % (songId))\n",
        "    # print(songName)\n",
        "    # producersQ = query_sparql(SongQueries.SONG_PRODUCER  % (songId))\n",
        "    # viewQ = query_sparql(SongQueries.SONG_VIEW  % (songId))\n",
        "    # print(othersQ)\n",
        "    flag = False\n",
        "    for p in othersQ[\"results\"][\"bindings\"]:\n",
        "        if \"performerLabel\" in p:\n",
        "            performer = p[\"performerLabel\"][\"value\"]\n",
        "            songs_data[\"performer\"].append(performer)\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"genreLabel\" in p:\n",
        "            genre = p[\"genreLabel\"][\"value\"]\n",
        "            songs_data[\"genres\"].append(genre)\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"labelLabel\" in p:\n",
        "            record_label = p[\"labelLabel\"][\"value\"]\n",
        "            songs_data[\"record_label\"].append(record_label)\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"producerLabel\" in p:\n",
        "            producer = p[\"producerLabel\"][\"value\"]\n",
        "            songs_data[\"producer\"].append(producer)\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"view\" in p:\n",
        "            #songs_data[\"yotube_view\"] = p[\"view\"][\"value\"]\n",
        "            for i, cutoff in enumerate(cutoff_values):\n",
        "                if int(p[\"view\"][\"value\"]) >= cutoff:\n",
        "                    songs_data[\"rating\"]= rating_val[i]\n",
        "                    break\n",
        "                elif int(p[\"view\"][\"value\"]) < cutoff_values[-1]:\n",
        "                    songs_data[\"rating\"]= rating_val[-1]\n",
        "                    break\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"instanceLabel\" in p:\n",
        "            inst = p[\"instanceLabel\"][\"value\"]\n",
        "            songs_data[\"instance_of\"].append(inst)\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"publication\" in p:\n",
        "            # Convert input string to datetime object\n",
        "            try:\n",
        "                dt = datetime.strptime(p[\"publication\"][\"value\"], '%Y-%m-%dT%H:%M:%SZ')\n",
        "                songs_data[\"publication_year\"] = dt.strftime(\"%Y\")\n",
        "                # Format datetime object to desired string format\n",
        "                output_string = dt.strftime('%B %d, %Y').replace(' 0', ' ')\n",
        "                songs_data[\"publication_date\"] = output_string\n",
        "            except ValueError:\n",
        "                # Ignore input string if it is not in the expected format\n",
        "                pass\n",
        "        else:\n",
        "            flag = True\n",
        "            break\n",
        "        if \"partLabel\" in p:\n",
        "            part = p[\"partLabel\"][\"value\"]\n",
        "            songs_data[\"from_album\"] = part\n",
        "            songs_data[\"is_from_album\"] = \"is from album\"\n",
        "        else:\n",
        "            songs_data[\"from_album\"] = 'N/A'\n",
        "            songs_data[\"is_from_album\"] = \"is a single\"\n",
        "        if \"tracklistLabel\" in p:\n",
        "            songs = p[\"tracklistLabel\"][\"value\"]\n",
        "            songs_data[\"songs_in_album\"].append(songs)\n",
        "\n",
        "    if flag == True:\n",
        "        continue\n",
        "\n",
        "    counter+=1\n",
        "    songs_data[\"name\"] = re.sub(r'_', ' ', urllib.parse.unquote(songName)).split(\" (\")[0]\n",
        "    songs_data[\"performer\"] = set(songs_data[\"performer\"])\n",
        "    songs_data[\"genres\"] = set(songs_data[\"genres\"])\n",
        "    songs_data[\"instance_of\"] = set(songs_data[\"instance_of\"])\n",
        "    songs_data[\"record_label\"] = set(songs_data[\"record_label\"])\n",
        "    songs_data[\"producer\"] = set(songs_data[\"producer\"])\n",
        "    songs_data[\"songs_in_album\"] = set(songs_data[\"songs_in_album\"])\n",
        "    all_data.append(songs_data)\n",
        "    song_ids.append(songId)\n",
        "    print(\"bar: \", len(all_data), 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2iok58aEt3u",
        "outputId": "dc360efd-748a-499f-9fe7-bed83cc412aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Q18786715',\n",
              " 'Q111397510',\n",
              " 'Q112654939',\n",
              " 'Q308895',\n",
              " 'Q76566134',\n",
              " 'Q192023',\n",
              " 'Q111784795',\n",
              " 'Q626490',\n",
              " 'Q2411420',\n",
              " 'Q161407',\n",
              " 'Q1995194',\n",
              " 'Q155894',\n",
              " 'Q18208944',\n",
              " 'Q592696',\n",
              " 'Q651472',\n",
              " 'Q62587323',\n",
              " 'Q111622181',\n",
              " 'Q1046717',\n",
              " 'Q1999714',\n",
              " 'Q108072305',\n",
              " 'Q2298481',\n",
              " 'Q1338452',\n",
              " 'Q1164996',\n",
              " 'Q1149738',\n",
              " 'Q1165404',\n",
              " 'Q581952',\n",
              " 'Q1330171',\n",
              " 'Q1420378',\n",
              " 'Q12207092',\n",
              " 'Q957616',\n",
              " 'Q18518749',\n",
              " 'Q16897727',\n",
              " 'Q19893560',\n",
              " 'Q19892483',\n",
              " 'Q27929592',\n",
              " 'Q3179698',\n",
              " 'Q2269723',\n",
              " 'Q15920900',\n",
              " 'Q18699094',\n",
              " 'Q384872',\n",
              " 'Q6412295',\n",
              " 'Q2277496',\n",
              " 'Q42854800',\n",
              " 'Q18844782',\n",
              " 'Q651633',\n",
              " 'Q74479041',\n",
              " 'Q1170299',\n",
              " 'Q1446083',\n",
              " 'Q6899069',\n",
              " 'Q3742015',\n",
              " 'Q7113407',\n",
              " 'Q2600214',\n",
              " 'Q2710119',\n",
              " 'Q15357783',\n",
              " 'Q64504565',\n",
              " 'Q30020390',\n",
              " 'Q2837589',\n",
              " 'Q5351571',\n",
              " 'Q21203631',\n",
              " 'Q1747485']"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_list = full + song_ids\n",
        "full_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "2kXEVgiPCmEW",
        "outputId": "96fba01f-6311-4ed9-ff66-d99883076888"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-240e7150-b47c-48ae-8f5d-875589def579\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>two_hop</th>\n",
              "      <th>three_hop</th>\n",
              "      <th>four_hop</th>\n",
              "      <th>five_hop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Style --&gt; performer --&gt; Taylor Swift --&gt; genr...</td>\n",
              "      <td>[Style --&gt; performer --&gt; Taylor Swift --&gt; genr...</td>\n",
              "      <td>[Style --&gt; performer --&gt; Taylor Swift --&gt; genr...</td>\n",
              "      <td>[Style --&gt; performer --&gt; Taylor Swift --&gt; genr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[As It Was --&gt; record label --&gt; Columbia Recor...</td>\n",
              "      <td>[As It Was --&gt; record label --&gt; Columbia Recor...</td>\n",
              "      <td>[As It Was --&gt; record label --&gt; Columbia Recor...</td>\n",
              "      <td>[As It Was --&gt; record label --&gt; Columbia Recor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Break My Soul --&gt; genre --&gt; house music --&gt; ~...</td>\n",
              "      <td>[Break My Soul --&gt; genre --&gt; house music --&gt; ~...</td>\n",
              "      <td>[Break My Soul --&gt; genre --&gt; house music --&gt; ~...</td>\n",
              "      <td>[Break My Soul --&gt; genre --&gt; house music --&gt; ~...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-240e7150-b47c-48ae-8f5d-875589def579')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-240e7150-b47c-48ae-8f5d-875589def579 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-240e7150-b47c-48ae-8f5d-875589def579');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             two_hop  \\\n",
              "0  [Style --> performer --> Taylor Swift --> genr...   \n",
              "1  [As It Was --> record label --> Columbia Recor...   \n",
              "2  [Break My Soul --> genre --> house music --> ~...   \n",
              "\n",
              "                                           three_hop  \\\n",
              "0  [Style --> performer --> Taylor Swift --> genr...   \n",
              "1  [As It Was --> record label --> Columbia Recor...   \n",
              "2  [Break My Soul --> genre --> house music --> ~...   \n",
              "\n",
              "                                            four_hop  \\\n",
              "0  [Style --> performer --> Taylor Swift --> genr...   \n",
              "1  [As It Was --> record label --> Columbia Recor...   \n",
              "2  [Break My Soul --> genre --> house music --> ~...   \n",
              "\n",
              "                                            five_hop  \n",
              "0  [Style --> performer --> Taylor Swift --> genr...  \n",
              "1  [As It Was --> record label --> Columbia Recor...  \n",
              "2  [Break My Soul --> genre --> house music --> ~...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(all_data)[[\"two_hop\", \"three_hop\", \"four_hop\", \"five_hop\"]]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK6NGRvn6ju3"
      },
      "outputs": [],
      "source": [
        "df.to_csv('song_select.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKFH8VV4liPi"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(all_data)[[\"two_hop\", \"three_hop\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNj94_uxmDAq"
      },
      "outputs": [],
      "source": [
        "combined_df = pd.concat([df, df1])\n",
        "combined_df.to_csv('song_select.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrMVAykkIxWn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_efSyeVpkED"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# assume your original dataframe is called \"df\"\n",
        "\n",
        "# create an empty list to store the results\n",
        "results = []\n",
        "\n",
        "# iterate over each row in the original dataframe\n",
        "for index, row in df.iterrows():\n",
        "    # iterate over each string in the \"two_hop\" column\n",
        "    for path in row['two_hop']:\n",
        "        # add a new dictionary to the results list\n",
        "        results.append({'path': path, 'num_hops': 2})\n",
        "\n",
        "    # iterate over each string in the \"three_hop\" column\n",
        "    for path in row['three_hop']:\n",
        "        # add a new dictionary to the results list\n",
        "        results.append({'path': path, 'num_hops': 3})\n",
        "\n",
        "    for path in row['four_hop']:\n",
        "        # add a new dictionary to the results list\n",
        "        results.append({'path': path, 'num_hops': 4})\n",
        "    for path in row['five_hop']:\n",
        "        # add a new dictionary to the results list\n",
        "        results.append({'path': path, 'num_hops': 5})\n",
        "\n",
        "# create a new dataframe from the results list\n",
        "new_df = pd.DataFrame(results)\n",
        "\n",
        "# print the resulting dataframe\n",
        "new_df.head(10)\n",
        "new_df.to_csv('/content/drive/MyDrive/org_paths.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVBN3KDk-lG2"
      },
      "outputs": [],
      "source": [
        "songs[songs.entity_type == \"song\"].sort_values(\"count\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk1-axji8DBi"
      },
      "outputs": [],
      "source": [
        "songs.groupby(\"entity_type\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx7jxYxr8FmA"
      },
      "outputs": [],
      "source": [
        "songs[[\"entity_type\", \"count\"]].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IDFcyM88OnA"
      },
      "outputs": [],
      "source": [
        "songs[songs.entity_type == \"song\"].reset_index()[[\"entity_type\", \"count\"]].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqG-wbrM8RlE"
      },
      "outputs": [],
      "source": [
        "song_edit = song.dropna(subset=[\"count\"])\n",
        "\n",
        "bucket_size = len(song_edit) // 10  # Determine the size of each bucket\n",
        "sorted_song = song_edit.sort_values(\"count\", ascending=False)  # Sort the DataFrame by count\n",
        "buckets = [sorted_song[i:i+bucket_size] for i in range(0, len(sorted_song), bucket_size)]  # Create a list of DataFrames for each bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBeKSqAkHLBb"
      },
      "outputs": [],
      "source": [
        "buckets[0].head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFB3blq3LnzE"
      },
      "outputs": [],
      "source": [
        "buckets[1].head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GZDUSHPLoqD"
      },
      "outputs": [],
      "source": [
        "buckets[2].head(20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}